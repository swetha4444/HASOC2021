{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_B.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0BIKpepLFFC"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beYyo1IupybQ",
        "outputId": "5268dc37-822b-49f0-e49a-5763235fe34a"
      },
      "source": [
        "!pip install -U torchtext==0.8.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.8.0\n",
            "  Downloading torchtext-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9 MB 9.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (2.23.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.9.0+cu102)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (4.62.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.8.0) (3.7.4.3)\n",
            "Installing collected packages: torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.10.0\n",
            "    Uninstalling torchtext-0.10.0:\n",
            "      Successfully uninstalled torchtext-0.10.0\n",
            "Successfully installed torchtext-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUL2CXL1p2v-",
        "outputId": "2a3daf97-0017-414a-91a8-deb20199d4c3"
      },
      "source": [
        "!pip install preprocessor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting preprocessor\n",
            "  Downloading preprocessor-1.1.3.tar.gz (4.2 kB)\n",
            "Building wheels for collected packages: preprocessor\n",
            "  Building wheel for preprocessor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for preprocessor: filename=preprocessor-1.1.3-py3-none-any.whl size=4477 sha256=daa22ae3f016fe12c4636022ed49339bbd95e7cc9e9067d45133a17eb722d61b\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/b7/36/aa37256db62b4bfd35a6f1b5536e9ba843f257b79dcbf3d5f1\n",
            "Successfully built preprocessor\n",
            "Installing collected packages: preprocessor\n",
            "Successfully installed preprocessor-1.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAZECI7Lp5-P"
      },
      "source": [
        "!pip install ktrain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86BDG_rup-c5"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from __future__ import division, print_function\n",
        "from gensim import models\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import word_tokenize\n",
        "import nltk\n",
        "import os\n",
        "import collections\n",
        "import re\n",
        "import string\n",
        "\n",
        "import preprocessor as p\n",
        "import ktrain\n",
        "from ktrain import text\n",
        "import nltk\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osbtFrIUvTpS"
      },
      "source": [
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"; "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "XZdcBF-Uq3A-",
        "outputId": "839a32d8-30ea-4238-9b1a-a6bb824034b5"
      },
      "source": [
        "df = pd.read_csv(\"preprocess_data.csv\",index_col=0)\n",
        "df= df.dropna()\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>_id</th>\n",
              "      <th>text</th>\n",
              "      <th>task_1</th>\n",
              "      <th>task_2</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4986</td>\n",
              "      <td>60c5d6bf5659ea5e55defa2c</td>\n",
              "      <td>@wealth if you made it through this &amp;amp;&amp;amp;...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>PRFN</td>\n",
              "      <td>made amp amp onli abl start make money sustain...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3394</td>\n",
              "      <td>60c5d6bf5659ea5e55def461</td>\n",
              "      <td>Technically that's still turning back the cloc...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>OFFN</td>\n",
              "      <td>technic still turn back clock dick head</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1310</td>\n",
              "      <td>60c5d6bf5659ea5e55defaad</td>\n",
              "      <td>@VMBJP @BJP4Bengal @BJP4India @narendramodi @J...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>govt stop think world media liber gang ani opt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3390</td>\n",
              "      <td>60c5d6bf5659ea5e55def419</td>\n",
              "      <td>@krtoprak_yigit Soldier of Japan Who has dick ...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>OFFN</td>\n",
              "      <td>soldier japan dick head</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4626</td>\n",
              "      <td>60c5d6bf5659ea5e55def7fa</td>\n",
              "      <td>@blueheartedly You'd be better off asking who ...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>OFFN</td>\n",
              "      <td>would better ask think sleazi shitbag lmao</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0.1  ...                                         text_clean\n",
              "0          4986  ...  made amp amp onli abl start make money sustain...\n",
              "1          3394  ...            technic still turn back clock dick head\n",
              "2          1310  ...  govt stop think world media liber gang ani opt...\n",
              "3          3390  ...                            soldier japan dick head\n",
              "4          4626  ...         would better ask think sleazi shitbag lmao\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAjZmDOPrYmP",
        "outputId": "e3a195d5-57d6-427a-ea51-1465f913f709"
      },
      "source": [
        "LE = LabelEncoder()\n",
        "LE.fit(df['task_2'])\n",
        "classes= list(LE.classes_)\n",
        "classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['HATE', 'NONE', 'OFFN', 'PRFN']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "Jg0Gvva0rG78",
        "outputId": "7157f7a5-30ec-42ec-d621-cb3c456f7c41"
      },
      "source": [
        "df['task_2'] = LE.fit_transform(df['task_2'])\n",
        "task1_params = dict(zip(LE.classes_, LE.transform(LE.classes_)))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>_id</th>\n",
              "      <th>text</th>\n",
              "      <th>task_1</th>\n",
              "      <th>task_2</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4986</td>\n",
              "      <td>60c5d6bf5659ea5e55defa2c</td>\n",
              "      <td>@wealth if you made it through this &amp;amp;&amp;amp;...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>3</td>\n",
              "      <td>made amp amp onli abl start make money sustain...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3394</td>\n",
              "      <td>60c5d6bf5659ea5e55def461</td>\n",
              "      <td>Technically that's still turning back the cloc...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>2</td>\n",
              "      <td>technic still turn back clock dick head</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1310</td>\n",
              "      <td>60c5d6bf5659ea5e55defaad</td>\n",
              "      <td>@VMBJP @BJP4Bengal @BJP4India @narendramodi @J...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>1</td>\n",
              "      <td>govt stop think world media liber gang ani opt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3390</td>\n",
              "      <td>60c5d6bf5659ea5e55def419</td>\n",
              "      <td>@krtoprak_yigit Soldier of Japan Who has dick ...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>2</td>\n",
              "      <td>soldier japan dick head</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4626</td>\n",
              "      <td>60c5d6bf5659ea5e55def7fa</td>\n",
              "      <td>@blueheartedly You'd be better off asking who ...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>2</td>\n",
              "      <td>would better ask think sleazi shitbag lmao</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0.1  ...                                         text_clean\n",
              "0          4986  ...  made amp amp onli abl start make money sustain...\n",
              "1          3394  ...            technic still turn back clock dick head\n",
              "2          1310  ...  govt stop think world media liber gang ani opt...\n",
              "3          3390  ...                            soldier japan dick head\n",
              "4          4626  ...         would better ask think sleazi shitbag lmao\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCTInWPrrMlK",
        "outputId": "c4e75740-fa9f-4889-aeb8-6d7bcf5672bf"
      },
      "source": [
        "LE.fit(df['task_2'])\n",
        "classes= list(LE.classes_)\n",
        "classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 1, 2, 3]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADXmoUjNreuP"
      },
      "source": [
        "# split train dataset into train, validation and test sets\n",
        "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text_clean'], df['task_2'], \n",
        "                                                                    random_state=42, \n",
        "                                                                    test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp9RrOF6rjUN"
      },
      "source": [
        "X_train = train_text.tolist()\n",
        "X_test = temp_text.tolist()\n",
        "\n",
        "y_train = train_labels.tolist()\n",
        "y_test = temp_labels.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "BOrstaiHrqv7",
        "outputId": "09a91af4-de7d-4ee9-c8cc-b9bedd8c41a1"
      },
      "source": [
        "import ktrain\n",
        "from ktrain import text\n",
        "MODEL_NAME = 'distilbert-base-uncased'  # replace this with model of choice\n",
        "t = text.Transformer(MODEL_NAME, maxlen=500, class_names=classes)\n",
        "trn = t.preprocess_train(X_train, y_train)\n",
        "val = t.preprocess_test(X_test, y_test)\n",
        "model = t.get_classifier()\n",
        "learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=6)\n",
        "history = learner.fit_onecycle(5e-5, 2)\n",
        "learner.validate(class_names=classes) # class_names must be string values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 14\n",
            "\t95percentile : 27\n",
            "\t99percentile : 31\n"
          ]
        },
        {
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n",
            "test sequence lengths:\n",
            "\tmean : 14\n",
            "\t95percentile : 27\n",
            "\t99percentile : 31\n"
          ]
        },
        {
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 5e-05...\n",
            "Epoch 1/2\n",
            "576/576 [==============================] - 7733s 13s/step - loss: 1.0506 - accuracy: 0.5520 - val_loss: 1.0080 - val_accuracy: 0.5599\n",
            "Epoch 2/2\n",
            "233/576 [===========>..................] - ETA: 1:15:02 - loss: 0.8624 - accuracy: 0.6538"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbPoyO9Ttl7l",
        "outputId": "f0cfda00-6aa4-4c75-f43a-8820e230fbc5"
      },
      "source": [
        "classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 1, 2, 3]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    }
  ]
}