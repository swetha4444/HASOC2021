{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "upset-insulin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation,Bidirectional,SpatialDropout1D\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ultimate-shame",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>_id</th>\n",
       "      <th>task_2</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4986</td>\n",
       "      <td>60c5d6bf5659ea5e55defa2c</td>\n",
       "      <td>PRFN</td>\n",
       "      <td>made amp amp onli abl start make money sustain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3394</td>\n",
       "      <td>60c5d6bf5659ea5e55def461</td>\n",
       "      <td>OFFN</td>\n",
       "      <td>technic still turn back clock dick head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1310</td>\n",
       "      <td>60c5d6bf5659ea5e55defaad</td>\n",
       "      <td>NONE</td>\n",
       "      <td>govt stop think world media liber gang ani opt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3390</td>\n",
       "      <td>60c5d6bf5659ea5e55def419</td>\n",
       "      <td>OFFN</td>\n",
       "      <td>soldier japan dick head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4626</td>\n",
       "      <td>60c5d6bf5659ea5e55def7fa</td>\n",
       "      <td>OFFN</td>\n",
       "      <td>would better ask think sleazi shitbag lmao</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1                       _id task_2  \\\n",
       "0          4986  60c5d6bf5659ea5e55defa2c   PRFN   \n",
       "1          3394  60c5d6bf5659ea5e55def461   OFFN   \n",
       "2          1310  60c5d6bf5659ea5e55defaad   NONE   \n",
       "3          3390  60c5d6bf5659ea5e55def419   OFFN   \n",
       "4          4626  60c5d6bf5659ea5e55def7fa   OFFN   \n",
       "\n",
       "                                          text_clean  \n",
       "0  made amp amp onli abl start make money sustain...  \n",
       "1            technic still turn back clock dick head  \n",
       "2  govt stop think world media liber gang ani opt...  \n",
       "3                            soldier japan dick head  \n",
       "4         would better ask think sleazi shitbag lmao  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('preprocess_data.csv')\n",
    "data.drop(['task_1','Unnamed: 0','text'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "piano-fairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = data['text_clean'].astype(str)\n",
    "tokenizer = Tokenizer(num_words = 1500,split=' ')\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "sequence = tokenizer.texts_to_sequences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "legitimate-program",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of unique words :  8255\n",
      "[[   0    0    0 ...  170    3  210]\n",
      " [   0    0    0 ...   72   54   73]\n",
      " [   0    0    0 ...    3   52   13]\n",
      " ...\n",
      " [   0    0    0 ...  817   45  156]\n",
      " [   0    0    0 ...  213   99   38]\n",
      " [   0    0    0 ... 1166  236   57]]\n"
     ]
    }
   ],
   "source": [
    "max_seq_len = 2500\n",
    "\n",
    "index_of_words = tokenizer.word_index\n",
    "print(\"No of unique words : \",len(index_of_words))\n",
    "\n",
    "X = pad_sequences(sequence , maxlen = max_seq_len )\n",
    "Y = data['task_2']\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "talented-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "vocabSize = len(index_of_words)\n",
    "lstm_out = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "institutional-luxembourg",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.15, random_state = 0)\n",
    "Y_true = Y_test\n",
    "Y_train = pd.get_dummies(Y_train).values\n",
    "Y_test = pd.get_dummies(Y_test).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "reasonable-statistics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 2500, 256)         2113280   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 2500, 256)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                82176     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 2,195,716\n",
      "Trainable params: 2,195,716\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabSize, embed_dim,input_length = 2500))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fuzzy-abuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(\"hasoc_b.h5\", monitor='val_loss', verbose=1, save_best_only=True,\n",
    "save_weights_only=False, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "noble-accused",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1358    NONE\n",
      "2200    HATE\n",
      "2337    PRFN\n",
      "3640    NONE\n",
      "2928    PRFN\n",
      "        ... \n",
      "472     PRFN\n",
      "15      PRFN\n",
      "1813    HATE\n",
      "1721    OFFN\n",
      "3690    PRFN\n",
      "Name: task_2, Length: 577, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(Y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "alone-launch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0]\n",
      " [1 0 0 0]\n",
      " [0 0 0 1]\n",
      " ...\n",
      " [1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_test)\n",
    "classes = ['HATE','NONE','PRFN','OFFN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "economic-separate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.4679 - accuracy: 0.5233\n",
      "Epoch 00001: val_loss improved from inf to 0.39771, saving model to hasoc_b.h5\n",
      "103/103 [==============================] - 613s 6s/step - loss: 0.4679 - accuracy: 0.5233 - val_loss: 0.3977 - val_accuracy: 0.6049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1da15983430>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train ,batch_size = 32, epochs = 1 ,validation_data=(X_test,Y_test) , callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "frozen-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "guided-damages",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10567279 0.78024745 0.07441134 0.03966843]\n",
      " [0.16810624 0.739315   0.06376564 0.02881311]\n",
      " [0.01539988 0.10032225 0.04804364 0.8362343 ]\n",
      " ...\n",
      " [0.57636255 0.20152661 0.20633763 0.01577327]\n",
      " [0.49971446 0.2997688  0.16714613 0.03337058]\n",
      " [0.02898476 0.2095538  0.07587679 0.68558466]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "handy-times",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 3, 1, 3, 3, 3, 1, 3, 0, 1, 3, 0, 3, 3, 3, 1, 3, 3, 1, 1, 0, 2, 0, 1, 3, 0, 2, 1, 3, 3, 3, 1, 3, 0, 3, 2, 3, 3, 0, 1, 1, 3, 2, 1, 1, 3, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 3, 3, 1, 0, 1, 3, 3, 1, 1, 3, 3, 2, 1, 3, 3, 1, 0, 1, 3, 1, 3, 0, 3, 3, 0, 3, 1, 3, 3, 3, 3, 1, 0, 0, 0, 1, 3, 1, 1, 3, 0, 0, 1, 3, 1, 3, 3, 0, 1, 2, 3, 3, 3, 3, 1, 2, 3, 0, 1, 1, 3, 1, 3, 3, 3, 1, 1, 1, 1, 3, 1, 1, 3, 3, 3, 0, 0, 0, 3, 0, 1, 3, 1, 3, 1, 3, 1, 1, 3, 1, 3, 3, 1, 1, 0, 1, 3, 1, 3, 3, 1, 1, 3, 1, 3, 1, 1, 0, 1, 3, 1, 3, 1, 1, 3, 1, 3, 1, 0, 1, 0, 3, 2, 1, 3, 3, 3, 1, 0, 0, 3, 1, 1, 1, 0, 3, 0, 1, 1, 3, 3, 1, 3, 3, 1, 2, 0, 3, 3, 0, 1, 1, 3, 1, 1, 1, 3, 0, 3, 1, 3, 3, 3, 3, 1, 0, 0, 0, 3, 3, 3, 1, 3, 1, 3, 1, 1, 1, 1, 2, 1, 3, 1, 3, 1, 2, 3, 1, 1, 1, 3, 3, 1, 1, 3, 0, 3, 1, 3, 3, 3, 3, 1, 3, 1, 3, 1, 1, 3, 3, 1, 1, 1, 1, 1, 3, 0, 3, 3, 1, 1, 0, 1, 3, 0, 3, 1, 0, 3, 1, 0, 0, 1, 3, 1, 1, 3, 3, 1, 1, 0, 0, 2, 3, 3, 0, 0, 3, 3, 1, 1, 1, 3, 0, 1, 0, 2, 1, 0, 1, 3, 1, 0, 1, 3, 1, 2, 3, 1, 1, 1, 1, 2, 3, 0, 3, 0, 1, 3, 0, 1, 3, 0, 1, 1, 3, 2, 3, 0, 3, 1, 3, 3, 1, 1, 3, 3, 3, 0, 3, 3, 0, 1, 1, 0, 3, 1, 3, 1, 3, 0, 3, 3, 2, 0, 1, 0, 0, 1, 1, 3, 3, 1, 1, 0, 1, 1, 3, 1, 1, 3, 3, 1, 3, 0, 3, 0, 3, 3, 3, 3, 0, 2, 3, 1, 1, 0, 3, 3, 1, 0, 1, 3, 1, 3, 3, 1, 1, 3, 0, 1, 1, 1, 3, 0, 1, 3, 2, 3, 0, 1, 3, 0, 1, 3, 1, 0, 1, 1, 3, 3, 1, 3, 3, 0, 1, 3, 1, 1, 3, 0, 3, 0, 1, 3, 3, 3, 2, 3, 2, 3, 0, 1, 1, 3, 1, 1, 0, 3, 3, 0, 1, 3, 3, 3, 1, 1, 3, 1, 3, 1, 1, 3, 0, 3, 1, 1, 2, 3, 1, 1, 0, 1, 3, 3, 2, 1, 1, 3, 0, 3, 1, 1, 3, 3, 1, 3, 0, 1, 0, 3, 0, 3, 0, 2, 3, 3, 3, 3, 2, 1, 3, 1, 1, 0, 2, 3, 1, 3, 1, 1, 1, 3, 0, 3, 1, 0, 3, 1, 1, 1, 3, 1, 1, 0, 3, 1, 0, 3, 1, 0, 1, 1, 0, 3, 0, 1, 3, 1, 3, 0, 1, 3, 3, 1, 3, 1, 0, 0, 3, 1, 1, 3, 1, 3, 3, 3, 0, 0, 3]\n",
      "[[0 1 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 0 1]\n",
      " ...\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "pred_class = []\n",
    "for i in Y_pred:\n",
    "    pred_class.append(np.argmax(i))\n",
    "print(pred_class)\n",
    "\n",
    "pred_class = pd.get_dummies(pred_class).values\n",
    "print(pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "blind-pricing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.44      0.42        96\n",
      "           1       0.62      0.70      0.66       197\n",
      "           2       0.35      0.09      0.14       104\n",
      "           3       0.71      0.89      0.79       180\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       577\n",
      "   macro avg       0.52      0.53      0.50       577\n",
      "weighted avg       0.56      0.60      0.57       577\n",
      " samples avg       0.60      0.60      0.60       577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test , pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-houston",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf] *",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
